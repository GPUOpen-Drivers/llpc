; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --tool lgc --version 5
; RUN: lgc --mcpu=gfx1201 -o - -passes="require<lgc-pipeline-state>,module(lgc-lower-desc),module(lgc-mutate-entry-point),function(lgc-lower-buffer-operations)" %s | FileCheck --check-prefixes=GFX12 %s
;;
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
 ;
 ;  Copyright (c) 2024-2025 Advanced Micro Devices, Inc. All Rights Reserved.
 ;
 ;  Permission is hereby granted, free of charge, to any person obtaining a copy
 ;  of this software and associated documentation files (the "Software"), to
 ;  deal in the Software without restriction, including without limitation the
 ;  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 ;  sell copies of the Software, and to permit persons to whom the Software is
 ;  furnished to do so, subject to the following conditions:
 ;
 ;  The above copyright notice and this permission notice shall be included in all
 ;  copies or substantial portions of the Software.
 ;
 ;  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 ;  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 ;  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 ;  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 ;  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 ;  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 ;  IN THE SOFTWARE.
 ;
 ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

define amdgpu_kernel void @strided_buffer_uniform_strided_load(<4 x i32> %desc, ptr %out) #0 !lgc.shaderstage !4 {
; GFX12-LABEL: define amdgpu_gfx void @strided_buffer_uniform_strided_load(
; GFX12-SAME: <4 x i32> [[DESC:%.*]], ptr [[OUT:%.*]], i32 inreg noundef [[GLOBALTABLE:%.*]], ptr addrspace(4) inreg noundef [[NUMWORKGROUPSPTR:%.*]], i32 inreg noundef [[USERDATA0:%.*]], i32 inreg noundef [[USERDATA1:%.*]], i32 inreg noundef [[USERDATA2:%.*]], i32 inreg noundef [[USERDATA3:%.*]], i32 inreg noundef [[USERDATA4:%.*]], i32 inreg noundef [[USERDATA5:%.*]], i32 inreg noundef [[PAD6:%.*]], i32 inreg noundef [[PAD7:%.*]], i32 inreg noundef [[PAD8:%.*]], i32 inreg noundef [[PAD9:%.*]], i32 inreg noundef [[PAD10:%.*]], i32 inreg noundef [[PAD11:%.*]], i32 inreg noundef [[SPILLTABLE:%.*]], i32 noundef [[LOCALINVOCATIONID:%.*]]) #[[ATTR0:[0-9]+]] !lgc.shaderstage [[META7:![0-9]+]] {
; GFX12-NEXT:  [[ENTRY:.*:]]
; GFX12-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; GFX12-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
; GFX12-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[SPILLTABLE]], i64 0
; GFX12-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to i64
; GFX12-NEXT:    [[TMP4:%.*]] = inttoptr i64 [[TMP3]] to ptr addrspace(4)
; GFX12-NEXT:    [[TMP5:%.*]] = insertelement <2 x i32> poison, i32 [[USERDATA4]], i64 0
; GFX12-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP5]], i32 [[USERDATA5]], i64 1
; GFX12-NEXT:    [[TMP7:%.*]] = bitcast <2 x i32> [[TMP6]] to i64
; GFX12-NEXT:    [[TMP8:%.*]] = bitcast i64 [[TMP7]] to <2 x i32>
; GFX12-NEXT:    [[TMP9:%.*]] = extractelement <2 x i32> [[TMP8]], i64 0
; GFX12-NEXT:    [[TMP10:%.*]] = extractelement <2 x i32> [[TMP8]], i64 1
; GFX12-NEXT:    [[TMP11:%.*]] = insertelement <4 x i32> poison, i32 [[TMP9]], i64 0
; GFX12-NEXT:    [[TMP12:%.*]] = or i32 [[TMP10]], 1048576
; GFX12-NEXT:    [[TMP13:%.*]] = insertelement <4 x i32> [[TMP11]], i32 [[TMP12]], i64 1
; GFX12-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP13]], i32 -1, i64 2
; GFX12-NEXT:    [[TMP15:%.*]] = insertelement <4 x i32> [[TMP14]], i32 838946732, i64 3
; GFX12-NEXT:    [[TMP16:%.*]] = extractelement <4 x i32> [[TMP15]], i64 1
; GFX12-NEXT:    [[TMP17:%.*]] = lshr i32 [[TMP16]], 16
; GFX12-NEXT:    [[TMP18:%.*]] = and i32 [[TMP17]], 16383
; GFX12-NEXT:    [[TMP19:%.*]] = mul i32 24, [[TMP18]]
; GFX12-NEXT:    [[TMP20:%.*]] = add i32 0, [[TMP19]]
; GFX12-NEXT:    [[TMP21:%.*]] = call i32 @llvm.amdgcn.s.buffer.load.i32(<4 x i32> [[TMP15]], i32 [[TMP20]], i32 0), !invariant.load [[META8:![0-9]+]]
; GFX12-NEXT:    [[TMP22:%.*]] = bitcast i32 [[TMP21]] to float
; GFX12-NEXT:    store float [[TMP22]], ptr [[OUT]], align 4
; GFX12-NEXT:    ret void
;
entry:
  %buf = call ptr addrspace(9) @lgc.load.strided.buffer.desc(i64 8589934592, i32 0, i32 0, i32 4, i32 16)
  %146 = call ptr @llvm.invariant.start.p9(i64 -1, ptr addrspace(9) %buf)
  %buf.idx = call ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9) %buf, i32 24)
  %res = load float, ptr addrspace(9) %buf.idx, align 4
  store float %res, ptr %out, align 4
  ret void
}

define amdgpu_kernel void @strided_buffer_uniform_strided_load_f16(<4 x i32> %desc, ptr %out) #0 !lgc.shaderstage !4 {
; GFX12-LABEL: define amdgpu_gfx void @strided_buffer_uniform_strided_load_f16(
; GFX12-SAME: <4 x i32> [[DESC:%.*]], ptr [[OUT:%.*]], i32 inreg noundef [[GLOBALTABLE:%.*]], ptr addrspace(4) inreg noundef [[NUMWORKGROUPSPTR:%.*]], i32 inreg noundef [[USERDATA0:%.*]], i32 inreg noundef [[USERDATA1:%.*]], i32 inreg noundef [[USERDATA2:%.*]], i32 inreg noundef [[USERDATA3:%.*]], i32 inreg noundef [[USERDATA4:%.*]], i32 inreg noundef [[USERDATA5:%.*]], i32 inreg noundef [[PAD6:%.*]], i32 inreg noundef [[PAD7:%.*]], i32 inreg noundef [[PAD8:%.*]], i32 inreg noundef [[PAD9:%.*]], i32 inreg noundef [[PAD10:%.*]], i32 inreg noundef [[PAD11:%.*]], i32 inreg noundef [[SPILLTABLE:%.*]], i32 noundef [[LOCALINVOCATIONID:%.*]]) #[[ATTR0]] !lgc.shaderstage [[META7]] {
; GFX12-NEXT:  [[ENTRY:.*:]]
; GFX12-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; GFX12-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
; GFX12-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[SPILLTABLE]], i64 0
; GFX12-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to i64
; GFX12-NEXT:    [[TMP4:%.*]] = inttoptr i64 [[TMP3]] to ptr addrspace(4)
; GFX12-NEXT:    [[TMP5:%.*]] = insertelement <2 x i32> poison, i32 [[USERDATA4]], i64 0
; GFX12-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP5]], i32 [[USERDATA5]], i64 1
; GFX12-NEXT:    [[TMP7:%.*]] = bitcast <2 x i32> [[TMP6]] to i64
; GFX12-NEXT:    [[TMP8:%.*]] = bitcast i64 [[TMP7]] to <2 x i32>
; GFX12-NEXT:    [[TMP9:%.*]] = extractelement <2 x i32> [[TMP8]], i64 0
; GFX12-NEXT:    [[TMP10:%.*]] = extractelement <2 x i32> [[TMP8]], i64 1
; GFX12-NEXT:    [[TMP11:%.*]] = insertelement <4 x i32> poison, i32 [[TMP9]], i64 0
; GFX12-NEXT:    [[TMP12:%.*]] = or i32 [[TMP10]], 1048576
; GFX12-NEXT:    [[TMP13:%.*]] = insertelement <4 x i32> [[TMP11]], i32 [[TMP12]], i64 1
; GFX12-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP13]], i32 -1, i64 2
; GFX12-NEXT:    [[TMP15:%.*]] = insertelement <4 x i32> [[TMP14]], i32 838946732, i64 3
; GFX12-NEXT:    [[TMP16:%.*]] = call i16 @llvm.amdgcn.struct.buffer.load.i16{{(\.v4i32)?}}(<4 x i32> [[TMP15]], i32 24, i32 0, i32 0, i32 0)
; GFX12-NEXT:    [[TMP17:%.*]] = bitcast i16 [[TMP16]] to half
; GFX12-NEXT:    store half [[TMP17]], ptr [[OUT]], align 2
; GFX12-NEXT:    ret void
;
entry:
  %buf = call ptr addrspace(9) @lgc.load.strided.buffer.desc(i64 8589934592, i32 0, i32 0, i32 4, i32 16)
  %146 = call ptr @llvm.invariant.start.p9(i64 -1, ptr addrspace(9) %buf)
  %buf.idx = call ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9) %buf, i32 24)
  %res = load half, ptr addrspace(9) %buf.idx, align 2
  store half %res, ptr %out, align 2
  ret void
}

define amdgpu_kernel void @strided_buffer_uniform_strided_load_i8(<4 x i32> %desc, ptr %out) #0 !lgc.shaderstage !4 {
; GFX12-LABEL: define amdgpu_gfx void @strided_buffer_uniform_strided_load_i8(
; GFX12-SAME: <4 x i32> [[DESC:%.*]], ptr [[OUT:%.*]], i32 inreg noundef [[GLOBALTABLE:%.*]], ptr addrspace(4) inreg noundef [[NUMWORKGROUPSPTR:%.*]], i32 inreg noundef [[USERDATA0:%.*]], i32 inreg noundef [[USERDATA1:%.*]], i32 inreg noundef [[USERDATA2:%.*]], i32 inreg noundef [[USERDATA3:%.*]], i32 inreg noundef [[USERDATA4:%.*]], i32 inreg noundef [[USERDATA5:%.*]], i32 inreg noundef [[PAD6:%.*]], i32 inreg noundef [[PAD7:%.*]], i32 inreg noundef [[PAD8:%.*]], i32 inreg noundef [[PAD9:%.*]], i32 inreg noundef [[PAD10:%.*]], i32 inreg noundef [[PAD11:%.*]], i32 inreg noundef [[SPILLTABLE:%.*]], i32 noundef [[LOCALINVOCATIONID:%.*]]) #[[ATTR0]] !lgc.shaderstage [[META7]] {
; GFX12-NEXT:  [[ENTRY:.*:]]
; GFX12-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; GFX12-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
; GFX12-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[SPILLTABLE]], i64 0
; GFX12-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to i64
; GFX12-NEXT:    [[TMP4:%.*]] = inttoptr i64 [[TMP3]] to ptr addrspace(4)
; GFX12-NEXT:    [[TMP5:%.*]] = insertelement <2 x i32> poison, i32 [[USERDATA4]], i64 0
; GFX12-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP5]], i32 [[USERDATA5]], i64 1
; GFX12-NEXT:    [[TMP7:%.*]] = bitcast <2 x i32> [[TMP6]] to i64
; GFX12-NEXT:    [[TMP8:%.*]] = bitcast i64 [[TMP7]] to <2 x i32>
; GFX12-NEXT:    [[TMP9:%.*]] = extractelement <2 x i32> [[TMP8]], i64 0
; GFX12-NEXT:    [[TMP10:%.*]] = extractelement <2 x i32> [[TMP8]], i64 1
; GFX12-NEXT:    [[TMP11:%.*]] = insertelement <4 x i32> poison, i32 [[TMP9]], i64 0
; GFX12-NEXT:    [[TMP12:%.*]] = or i32 [[TMP10]], 1048576
; GFX12-NEXT:    [[TMP13:%.*]] = insertelement <4 x i32> [[TMP11]], i32 [[TMP12]], i64 1
; GFX12-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP13]], i32 -1, i64 2
; GFX12-NEXT:    [[TMP15:%.*]] = insertelement <4 x i32> [[TMP14]], i32 838946732, i64 3
; GFX12-NEXT:    [[TMP16:%.*]] = call i8 @llvm.amdgcn.struct.buffer.load.i8{{(\.v4i32)?}}(<4 x i32> [[TMP15]], i32 24, i32 0, i32 0, i32 0)
; GFX12-NEXT:    store i8 [[TMP16]], ptr [[OUT]], align 1
; GFX12-NEXT:    ret void
;
entry:
  %buf = call ptr addrspace(9) @lgc.load.strided.buffer.desc(i64 8589934592, i32 0, i32 0, i32 4, i32 16)
  %146 = call ptr @llvm.invariant.start.p9(i64 -1, ptr addrspace(9) %buf)
  %buf.idx = call ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9) %buf, i32 24)
  %res = load i8, ptr addrspace(9) %buf.idx, align 1
  store i8 %res, ptr %out, align 1
  ret void
}

define amdgpu_kernel void @strided_buffer_uniform_strided_load_v4i32(<4 x i32> %desc, ptr %out) #0 !lgc.shaderstage !4 {
; GFX12-LABEL: define amdgpu_gfx void @strided_buffer_uniform_strided_load_v4i32(
; GFX12-SAME: <4 x i32> [[DESC:%.*]], ptr [[OUT:%.*]], i32 inreg noundef [[GLOBALTABLE:%.*]], ptr addrspace(4) inreg noundef [[NUMWORKGROUPSPTR:%.*]], i32 inreg noundef [[USERDATA0:%.*]], i32 inreg noundef [[USERDATA1:%.*]], i32 inreg noundef [[USERDATA2:%.*]], i32 inreg noundef [[USERDATA3:%.*]], i32 inreg noundef [[USERDATA4:%.*]], i32 inreg noundef [[USERDATA5:%.*]], i32 inreg noundef [[PAD6:%.*]], i32 inreg noundef [[PAD7:%.*]], i32 inreg noundef [[PAD8:%.*]], i32 inreg noundef [[PAD9:%.*]], i32 inreg noundef [[PAD10:%.*]], i32 inreg noundef [[PAD11:%.*]], i32 inreg noundef [[SPILLTABLE:%.*]], i32 noundef [[LOCALINVOCATIONID:%.*]]) #[[ATTR0]] !lgc.shaderstage [[META7]] {
; GFX12-NEXT:  [[ENTRY:.*:]]
; GFX12-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; GFX12-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
; GFX12-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[SPILLTABLE]], i64 0
; GFX12-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to i64
; GFX12-NEXT:    [[TMP4:%.*]] = inttoptr i64 [[TMP3]] to ptr addrspace(4)
; GFX12-NEXT:    [[TMP5:%.*]] = insertelement <2 x i32> poison, i32 [[USERDATA4]], i64 0
; GFX12-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP5]], i32 [[USERDATA5]], i64 1
; GFX12-NEXT:    [[TMP7:%.*]] = bitcast <2 x i32> [[TMP6]] to i64
; GFX12-NEXT:    [[TMP8:%.*]] = bitcast i64 [[TMP7]] to <2 x i32>
; GFX12-NEXT:    [[TMP9:%.*]] = extractelement <2 x i32> [[TMP8]], i64 0
; GFX12-NEXT:    [[TMP10:%.*]] = extractelement <2 x i32> [[TMP8]], i64 1
; GFX12-NEXT:    [[TMP11:%.*]] = insertelement <4 x i32> poison, i32 [[TMP9]], i64 0
; GFX12-NEXT:    [[TMP12:%.*]] = or i32 [[TMP10]], 1048576
; GFX12-NEXT:    [[TMP13:%.*]] = insertelement <4 x i32> [[TMP11]], i32 [[TMP12]], i64 1
; GFX12-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP13]], i32 -1, i64 2
; GFX12-NEXT:    [[TMP15:%.*]] = insertelement <4 x i32> [[TMP14]], i32 838946732, i64 3
; GFX12-NEXT:    [[TMP21:%.*]] = extractelement <4 x i32> [[TMP15]], i64 1
; GFX12-NEXT:    [[TMP17:%.*]] = lshr i32 [[TMP21]], 16
; GFX12-NEXT:    [[TMP18:%.*]] = and i32 [[TMP17]], 16383
; GFX12-NEXT:    [[TMP19:%.*]] = mul i32 24, [[TMP18]]
; GFX12-NEXT:    [[TMP20:%.*]] = add i32 0, [[TMP19]]
; GFX12-NEXT:    [[TMP16:%.*]] = call <4 x i32> @llvm.amdgcn.s.buffer.load.v4i32(<4 x i32> [[TMP15]], i32 [[TMP20]], i32 0), !invariant.load [[META8]]
; GFX12-NEXT:    store <4 x i32> [[TMP16]], ptr [[OUT]], align 16
; GFX12-NEXT:    ret void
;
entry:
  %buf = call ptr addrspace(9) @lgc.load.strided.buffer.desc(i64 8589934592, i32 0, i32 0, i32 4, i32 16)
  %146 = call ptr @llvm.invariant.start.p9(i64 -1, ptr addrspace(9) %buf)
  %buf.idx = call ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9) %buf, i32 24)
  %res = load <4 x i32>, ptr addrspace(9) %buf.idx, align 16
  store <4 x i32>  %res, ptr %out, align 16
  ret void
}

define amdgpu_kernel void @strided_buffer_convert_uniform_strided_load(<4 x i32> inreg %desc, ptr %out) #0 !lgc.shaderstage !4 {
; GFX12-LABEL: define amdgpu_gfx void @strided_buffer_convert_uniform_strided_load(
; GFX12-SAME: <4 x i32> inreg [[DESC:%.*]], ptr [[OUT:%.*]], i32 inreg noundef [[GLOBALTABLE:%.*]], ptr addrspace(4) inreg noundef [[NUMWORKGROUPSPTR:%.*]], i32 inreg noundef [[USERDATA0:%.*]], i32 inreg noundef [[USERDATA1:%.*]], i32 inreg noundef [[USERDATA2:%.*]], i32 inreg noundef [[USERDATA3:%.*]], i32 inreg noundef [[USERDATA4:%.*]], i32 inreg noundef [[USERDATA5:%.*]], i32 inreg noundef [[PAD6:%.*]], i32 inreg noundef [[PAD7:%.*]], i32 inreg noundef [[PAD8:%.*]], i32 inreg noundef [[PAD9:%.*]], i32 inreg noundef [[PAD10:%.*]], i32 inreg noundef [[PAD11:%.*]], i32 inreg noundef [[SPILLTABLE:%.*]], i32 noundef [[LOCALINVOCATIONID:%.*]]) #[[ATTR0]] !lgc.shaderstage [[META7]] {
; GFX12-NEXT:  [[ENTRY:.*:]]
; GFX12-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; GFX12-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
; GFX12-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[SPILLTABLE]], i64 0
; GFX12-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to i64
; GFX12-NEXT:    [[TMP4:%.*]] = inttoptr i64 [[TMP3]] to ptr addrspace(4)
; GFX12-NEXT:    [[TMP5:%.*]] = extractelement <4 x i32> [[DESC]], i64 1
; GFX12-NEXT:    [[TMP6:%.*]] = and i32 [[TMP5]], -1073676289
; GFX12-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 786432
; GFX12-NEXT:    [[TMP8:%.*]] = insertelement <4 x i32> [[DESC]], i32 [[TMP7]], i64 1
; GFX12-NEXT:    [[TMP12:%.*]] = extractelement <4 x i32> [[TMP8]], i64 3
; GFX12-NEXT:    [[TMP13:%.*]] = and i32 [[TMP12]], -805306369
; GFX12-NEXT:    [[TMP11:%.*]] = or i32 [[TMP13]], 536870912
; GFX12-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP8]], i32 [[TMP11]], i64 3
; GFX12-NEXT:    [[TMP16:%.*]] = call i32 @llvm.amdgcn.s.buffer.load.i32{{(\.v4i32)?}}(<4 x i32> [[DESC]], i32 add (i32 ptrtoint (ptr addrspace(6) getelementptr inbounds (i8, ptr addrspace(6) null, i32 8) to i32), i32 288), i32 0), !invariant.load [[META8]]
; GFX12-NEXT:    [[TMP17:%.*]] = bitcast i32 [[TMP16]] to float
; GFX12-NEXT:    store float [[TMP17]], ptr [[OUT]], align 4
; GFX12-NEXT:    ret void
;
entry:
  %ptr = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> %desc, i1 false)
  %146 = call ptr @llvm.invariant.start.p7(i64 -1, ptr addrspace(7) %ptr)
  %buf.off = getelementptr inbounds i8, ptr addrspace(7) %ptr, i32 8
  %buf.cnv = call ptr addrspace(9) @lgc.convert.to.strided.buffer.pointer(ptr addrspace(7) %buf.off, i32 12)
  %buf.idx = call ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9) %buf.cnv, i32 24)
  %res = load float, ptr addrspace(9) %buf.idx, align 4
  store float %res, ptr %out, align 4
  ret void
}

define amdgpu_kernel void @strided_buffer_convert_uniform_strided_load_f16(<4 x i32> inreg %desc, ptr %out) #0 !lgc.shaderstage !4 {
; GFX12-LABEL: define amdgpu_gfx void @strided_buffer_convert_uniform_strided_load_f16(
; GFX12-SAME: <4 x i32> inreg [[DESC:%.*]], ptr [[OUT:%.*]], i32 inreg noundef [[GLOBALTABLE:%.*]], ptr addrspace(4) inreg noundef [[NUMWORKGROUPSPTR:%.*]], i32 inreg noundef [[USERDATA0:%.*]], i32 inreg noundef [[USERDATA1:%.*]], i32 inreg noundef [[USERDATA2:%.*]], i32 inreg noundef [[USERDATA3:%.*]], i32 inreg noundef [[USERDATA4:%.*]], i32 inreg noundef [[USERDATA5:%.*]], i32 inreg noundef [[PAD6:%.*]], i32 inreg noundef [[PAD7:%.*]], i32 inreg noundef [[PAD8:%.*]], i32 inreg noundef [[PAD9:%.*]], i32 inreg noundef [[PAD10:%.*]], i32 inreg noundef [[PAD11:%.*]], i32 inreg noundef [[SPILLTABLE:%.*]], i32 noundef [[LOCALINVOCATIONID:%.*]]) #[[ATTR0]] !lgc.shaderstage [[META7]] {
; GFX12-NEXT:  [[ENTRY:.*:]]
; GFX12-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; GFX12-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
; GFX12-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[SPILLTABLE]], i64 0
; GFX12-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to i64
; GFX12-NEXT:    [[TMP4:%.*]] = inttoptr i64 [[TMP3]] to ptr addrspace(4)
; GFX12-NEXT:    [[TMP5:%.*]] = extractelement <4 x i32> [[DESC]], i64 1
; GFX12-NEXT:    [[TMP6:%.*]] = and i32 [[TMP5]], -1073676289
; GFX12-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 786432
; GFX12-NEXT:    [[TMP8:%.*]] = insertelement <4 x i32> [[DESC]], i32 [[TMP7]], i64 1
; GFX12-NEXT:    [[TMP12:%.*]] = extractelement <4 x i32> [[TMP8]], i64 3
; GFX12-NEXT:    [[TMP13:%.*]] = and i32 [[TMP12]], -805306369
; GFX12-NEXT:    [[TMP11:%.*]] = or i32 [[TMP13]], 536870912
; GFX12-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP8]], i32 [[TMP11]], i64 3
; GFX12-NEXT:    [[TMP16:%.*]] = call i16 @llvm.amdgcn.struct.buffer.load.i16{{(\.v4i32)?}}(<4 x i32> [[TMP14]], i32 24, i32 ptrtoint (ptr addrspace(6) getelementptr inbounds (i8, ptr addrspace(6) null, i32 8) to i32), i32 0, i32 0)
; GFX12-NEXT:    [[TMP17:%.*]] = bitcast i16 [[TMP16]] to half
; GFX12-NEXT:    store half [[TMP17]], ptr [[OUT]], align 2
; GFX12-NEXT:    ret void
;
entry:
  %ptr = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> %desc, i1 false)
  %146 = call ptr @llvm.invariant.start.p7(i64 -1, ptr addrspace(7) %ptr)
  %buf.off = getelementptr inbounds i8, ptr addrspace(7) %ptr, i32 8
  %buf.cnv = call ptr addrspace(9) @lgc.convert.to.strided.buffer.pointer(ptr addrspace(7) %buf.off, i32 12)
  %buf.idx = call ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9) %buf.cnv, i32 24)
  %res = load half, ptr addrspace(9) %buf.idx, align 2
  store half %res, ptr %out, align 2
  ret void
}

define amdgpu_kernel void @strided_buffer_convert_uniform_strided_load_i8(<4 x i32> inreg %desc, ptr %out) #0 !lgc.shaderstage !4 {
; GFX12-LABEL: define amdgpu_gfx void @strided_buffer_convert_uniform_strided_load_i8(
; GFX12-SAME: <4 x i32> inreg [[DESC:%.*]], ptr [[OUT:%.*]], i32 inreg noundef [[GLOBALTABLE:%.*]], ptr addrspace(4) inreg noundef [[NUMWORKGROUPSPTR:%.*]], i32 inreg noundef [[USERDATA0:%.*]], i32 inreg noundef [[USERDATA1:%.*]], i32 inreg noundef [[USERDATA2:%.*]], i32 inreg noundef [[USERDATA3:%.*]], i32 inreg noundef [[USERDATA4:%.*]], i32 inreg noundef [[USERDATA5:%.*]], i32 inreg noundef [[PAD6:%.*]], i32 inreg noundef [[PAD7:%.*]], i32 inreg noundef [[PAD8:%.*]], i32 inreg noundef [[PAD9:%.*]], i32 inreg noundef [[PAD10:%.*]], i32 inreg noundef [[PAD11:%.*]], i32 inreg noundef [[SPILLTABLE:%.*]], i32 noundef [[LOCALINVOCATIONID:%.*]]) #[[ATTR0]] !lgc.shaderstage [[META7]] {
; GFX12-NEXT:  [[ENTRY:.*:]]
; GFX12-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; GFX12-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
; GFX12-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[SPILLTABLE]], i64 0
; GFX12-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to i64
; GFX12-NEXT:    [[TMP4:%.*]] = inttoptr i64 [[TMP3]] to ptr addrspace(4)
; GFX12-NEXT:    [[TMP5:%.*]] = extractelement <4 x i32> [[DESC]], i64 1
; GFX12-NEXT:    [[TMP6:%.*]] = and i32 [[TMP5]], -1073676289
; GFX12-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 786432
; GFX12-NEXT:    [[TMP8:%.*]] = insertelement <4 x i32> [[DESC]], i32 [[TMP7]], i64 1
; GFX12-NEXT:    [[TMP12:%.*]] = extractelement <4 x i32> [[TMP8]], i64 3
; GFX12-NEXT:    [[TMP13:%.*]] = and i32 [[TMP12]], -805306369
; GFX12-NEXT:    [[TMP11:%.*]] = or i32 [[TMP13]], 536870912
; GFX12-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP8]], i32 [[TMP11]], i64 3
; GFX12-NEXT:    [[TMP16:%.*]] = call i8 @llvm.amdgcn.struct.buffer.load.i8{{(\.v4i32)?}}(<4 x i32> [[TMP14]], i32 24, i32 ptrtoint (ptr addrspace(6) getelementptr inbounds (i8, ptr addrspace(6) null, i32 8) to i32), i32 0, i32 0)
; GFX12-NEXT:    store i8 [[TMP16]], ptr [[OUT]], align 1
; GFX12-NEXT:    ret void
;
entry:
  %ptr = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> %desc, i1 false)
  %146 = call ptr @llvm.invariant.start.p7(i64 -1, ptr addrspace(7) %ptr)
  %buf.off = getelementptr inbounds i8, ptr addrspace(7) %ptr, i32 8
  %buf.cnv = call ptr addrspace(9) @lgc.convert.to.strided.buffer.pointer(ptr addrspace(7) %buf.off, i32 12)
  %buf.idx = call ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9) %buf.cnv, i32 24)
  %res = load i8, ptr addrspace(9) %buf.idx, align 1
  store i8 %res, ptr %out, align 1
  ret void
}

define amdgpu_kernel void @strided_buffer_convert_uniform_strided_load_v4i32(<4 x i32> inreg %desc, ptr %out) #0 !lgc.shaderstage !4 {
; GFX12-LABEL: define amdgpu_gfx void @strided_buffer_convert_uniform_strided_load_v4i32(
; GFX12-SAME: <4 x i32> inreg [[DESC:%.*]], ptr [[OUT:%.*]], i32 inreg noundef [[GLOBALTABLE:%.*]], ptr addrspace(4) inreg noundef [[NUMWORKGROUPSPTR:%.*]], i32 inreg noundef [[USERDATA0:%.*]], i32 inreg noundef [[USERDATA1:%.*]], i32 inreg noundef [[USERDATA2:%.*]], i32 inreg noundef [[USERDATA3:%.*]], i32 inreg noundef [[USERDATA4:%.*]], i32 inreg noundef [[USERDATA5:%.*]], i32 inreg noundef [[PAD6:%.*]], i32 inreg noundef [[PAD7:%.*]], i32 inreg noundef [[PAD8:%.*]], i32 inreg noundef [[PAD9:%.*]], i32 inreg noundef [[PAD10:%.*]], i32 inreg noundef [[PAD11:%.*]], i32 inreg noundef [[SPILLTABLE:%.*]], i32 noundef [[LOCALINVOCATIONID:%.*]]) #[[ATTR0]] !lgc.shaderstage [[META7]] {
; GFX12-NEXT:  [[ENTRY:.*:]]
; GFX12-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; GFX12-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
; GFX12-NEXT:    [[TMP2:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[SPILLTABLE]], i64 0
; GFX12-NEXT:    [[TMP3:%.*]] = bitcast <2 x i32> [[TMP2]] to i64
; GFX12-NEXT:    [[TMP4:%.*]] = inttoptr i64 [[TMP3]] to ptr addrspace(4)
; GFX12-NEXT:    [[TMP5:%.*]] = extractelement <4 x i32> [[DESC]], i64 1
; GFX12-NEXT:    [[TMP6:%.*]] = and i32 [[TMP5]], -1073676289
; GFX12-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 786432
; GFX12-NEXT:    [[TMP8:%.*]] = insertelement <4 x i32> [[DESC]], i32 [[TMP7]], i64 1
; GFX12-NEXT:    [[TMP12:%.*]] = extractelement <4 x i32> [[TMP8]], i64 3
; GFX12-NEXT:    [[TMP13:%.*]] = and i32 [[TMP12]], -805306369
; GFX12-NEXT:    [[TMP11:%.*]] = or i32 [[TMP13]], 536870912
; GFX12-NEXT:    [[TMP14:%.*]] = insertelement <4 x i32> [[TMP8]], i32 [[TMP11]], i64 3
; GFX12-NEXT:    [[TMP16:%.*]] = call <4 x i32> @llvm.amdgcn.s.buffer.load.v4i32(<4 x i32> [[DESC]], i32 add (i32 ptrtoint (ptr addrspace(6) getelementptr inbounds (i8, ptr addrspace(6) null, i32 8) to i32), i32 288), i32 0), !invariant.load [[META8]]
; GFX12-NEXT:    store <4 x i32> [[TMP16]], ptr [[OUT]], align 16
; GFX12-NEXT:    ret void
;
entry:
  %ptr = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> %desc, i1 false)
  %146 = call ptr @llvm.invariant.start.p7(i64 -1, ptr addrspace(7) %ptr)
  %buf.off = getelementptr inbounds i8, ptr addrspace(7) %ptr, i32 8
  %buf.cnv = call ptr addrspace(9) @lgc.convert.to.strided.buffer.pointer(ptr addrspace(7) %buf.off, i32 12)
  %buf.idx = call ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9) %buf.cnv, i32 24)
  %res = load <4 x i32>, ptr addrspace(9) %buf.idx, align 16
  store <4 x i32> %res, ptr %out, align 16
  ret void
}

declare ptr addrspace(9) @lgc.load.strided.buffer.desc(i64, i32, i32, i32, i32) #0
declare ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32>, i1) nounwind readnone
declare ptr addrspace(9) @lgc.convert.to.strided.buffer.pointer(ptr addrspace(7), i32)
declare ptr addrspace(7) @lgc.buffer.load.desc.to.ptr(ptr addrspace(4), i1, i1) nounwind readnone
declare ptr addrspace(9) @lgc.strided.index.add(ptr addrspace(9), i32) #0

attributes #0 = { nounwind willreturn memory(none) }

!llpc.compute.mode = !{!0}

!lgc.user.data.nodes = !{!1, !2, !3}

!0 = !{i32 16, i32 16, i32 1}
!1 = !{!"DescriptorTableVaPtr", i32 7, i32 255, i32 3, i32 1, i32 1}
!2 = !{!"DescriptorMutable", i32 17, i32 0, i32 0, i32 40, i64 4294967296, i32 0, i32 8}
!3 = !{!"DescriptorConstBufferCompact", i32 15, i32 255, i32 4, i32 2, i64 8589934592, i32 0, i32 2}
!4 = !{i32 7}
;.
; GFX12: [[META7]] = !{i32 7}
; GFX12: [[META8]] = !{}
;.
