/*
 ***********************************************************************************************************************
 *
 *  Copyright (c) 2024-2025 Advanced Micro Devices, Inc. All Rights Reserved.
 *
 *  Permission is hereby granted, free of charge, to any person obtaining a copy
 *  of this software and associated documentation files (the "Software"), to
 *  deal in the Software without restriction, including without limitation the
 *  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 *  sell copies of the Software, and to permit persons to whom the Software is
 *  furnished to do so, subject to the following conditions:
 *
 *  The above copyright notice and this permission notice shall be included in all
 *  copies or substantial portions of the Software.
 *
 *  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 *  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 *  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 *  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 *  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 *  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 *  IN THE SOFTWARE.
 *
 **********************************************************************************************************************/

// NOTE: Assertions have been autogenerated by tool/update_llpc_test_checks.py
// RUN: amdllpc -o - -gfxip 12.0.1 -filetype=asm %s | FileCheck -check-prefixes=CHECK %s
#version 450

#extension GL_KHR_shader_subgroup_quad : require

layout(binding = 0) readonly buffer Block0
{
    float alpha[];
};

layout(location = 0) out vec4 color;

void main()
{
    ivec2 coord = ivec2(gl_FragCoord.xy);
    float v = alpha[coord.y * 2 + coord.x];

    vec4 lanes;
    for (uint i = 0; i < 4; ++i) {
        lanes[i] = subgroupQuadBroadcast(v, i);
    }

    color = lanes;
}
// CHECK-LABEL: amdgpu_ps_main:
// CHECK:         s_mov_b64 s[4:5], exec
// CHECK-NEXT:    s_wqm_b64 exec, exec
// CHECK-NEXT:    s_getpc_b64 s[2:3]
// CHECK-NEXT:    s_mov_b32 s0, s1
// CHECK-NEXT:    s_sext_i32_i16 s3, s3
// CHECK-NEXT:    v_cvt_i32_f32_e32 v0, v2
// CHECK-NEXT:    s_mov_b32 s1, s3
// CHECK-NEXT:    v_cvt_i32_f32_e32 v1, v3
// CHECK-NEXT:    s_load_b128 s[0:3], s[0:1], 0x0
// CHECK-NEXT:    s_delay_alu instid0(VALU_DEP_2) | instskip(NEXT) | instid1(VALU_DEP_1)
// CHECK-NEXT:    v_lshlrev_b32_e32 v0, 2, v0
// CHECK-NEXT:    v_lshl_add_u32 v0, v1, 3, v0
// CHECK-NEXT:    v_mbcnt_lo_u32_b32 v1, -1, 0
// CHECK-NEXT:    s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1)
// CHECK-NEXT:    v_mbcnt_hi_u32_b32 v1, -1, v1
// CHECK-NEXT:    v_and_b32_e32 v2, 0x7c, v1
// CHECK-NEXT:    v_or_b32_e32 v1, 3, v1
// CHECK-NEXT:    s_wait_kmcnt 0x0
// CHECK-NEXT:    buffer_load_b32 v0, v0, s[0:3], null offen
// CHECK-NEXT:    v_or_b32_e32 v3, 1, v2
// CHECK-NEXT:    v_or_b32_e32 v4, 2, v2
// CHECK-NEXT:    s_wait_loadcnt 0x0
// CHECK-NEXT:    v_permlane16_var_b32 v2, v0, v2 op_sel:[0,1]
// CHECK-NEXT:    s_delay_alu instid0(VALU_DEP_3) | instskip(NEXT) | instid1(VALU_DEP_3)
// CHECK-NEXT:    v_permlane16_var_b32 v3, v0, v3 op_sel:[0,1]
// CHECK-NEXT:    v_permlane16_var_b32 v4, v0, v4 op_sel:[0,1]
// CHECK-NEXT:    v_permlane16_var_b32 v0, v0, v1 op_sel:[0,1]
// CHECK-NEXT:    s_and_b64 exec, exec, s[4:5]
// CHECK-NEXT:    export mrt0 v2, v3, v4, v0 done
// CHECK-NEXT:    s_endpgm
