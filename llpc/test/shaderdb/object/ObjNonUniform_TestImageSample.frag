// NOTE: Assertions have been autogenerated by tool/update_llpc_test_checks.py UTC_ARGS: --version 5
#version 450
/*
 ***********************************************************************************************************************
 *
 *  Copyright (c) 2024-2025 Advanced Micro Devices, Inc. All Rights Reserved.
 *
 *  Permission is hereby granted, free of charge, to any person obtaining a copy
 *  of this software and associated documentation files (the "Software"), to
 *  deal in the Software without restriction, including without limitation the
 *  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
 *  sell copies of the Software, and to permit persons to whom the Software is
 *  furnished to do so, subject to the following conditions:
 *
 *  The above copyright notice and this permission notice shall be included in all
 *  copies or substantial portions of the Software.
 *
 *  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 *  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 *  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 *  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 *  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 *  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 *  IN THE SOFTWARE.
 *
 **********************************************************************************************************************/
// RUN: amdllpc --print-after=lgc-builder-replayer %s 2>&1 | FileCheck -check-prefix=SHADERTEST %s
#extension GL_EXT_nonuniform_qualifier : require
layout(set=0,binding=0) uniform sampler2D samp2Ds[];
layout(set=0,binding=1) uniform sampler2D samp2D;
layout(set=0,binding=2) uniform sampler samp;
layout(set=0,binding=3) uniform texture2D image;
layout(set=0,binding=4) uniform sampler samps[];
layout(set=0,binding=5) uniform texture2D images[];

layout(location = 0) out vec4     FragColor;
layout(location = 0) in flat int  index1;
layout(location = 1) in flat int  index2;

void main()
{
  vec4 color1 = vec4(0);
  color1 += texture(samp2D, vec2(0, 0));
  color1 += texture(sampler2D(image, samp), vec2(0,0));
  color1 += texture(samp2Ds[0], vec2(0,0));
  color1 += texture(sampler2D(images[index1], samps[index2]), vec2(0, 0));

  color1 += texture(nonuniformEXT(sampler2D(images[index1], samp)), vec2(0,0));

  FragColor = color1;
}
// SHADERTEST-LABEL: define dllexport spir_func void @lgc.shader.FS.main(
// SHADERTEST-SAME: ) local_unnamed_addr #[[ATTR0:[0-9]+]] !spirv.ExecutionModel [[META14:![0-9]+]] !lgc.shaderstage [[META15:![0-9]+]] {
// SHADERTEST-NEXT:  [[_ENTRY:.*:]]
// SHADERTEST-NEXT:    [[TMP0:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP1:%.*]] = bitcast i64 [[TMP0]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP2:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP3:%.*]] = bitcast i64 [[TMP2]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP4:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP5:%.*]] = bitcast i64 [[TMP4]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP6:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP7:%.*]] = bitcast i64 [[TMP6]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP8:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP9:%.*]] = bitcast i64 [[TMP8]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP10:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP11:%.*]] = bitcast i64 [[TMP10]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP12:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP13:%.*]] = bitcast i64 [[TMP12]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP14:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP15:%.*]] = bitcast i64 [[TMP14]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP16:%.*]] = call i64 @llvm.amdgcn.s.getpc()
// SHADERTEST-NEXT:    [[TMP17:%.*]] = bitcast i64 [[TMP16]] to <2 x i32>
// SHADERTEST-NEXT:    [[TMP18:%.*]] = call i32 (...) @lgc.input.import.interpolated__i32(i1 false, i32 1, i32 0, i32 0, i32 poison, i32 1, i32 poison)
// SHADERTEST-NEXT:    [[TMP19:%.*]] = call i32 (...) @lgc.input.import.interpolated__i32(i1 false, i32 0, i32 0, i32 0, i32 poison, i32 1, i32 poison)
// SHADERTEST-NEXT:    [[TMP20:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
// SHADERTEST-NEXT:    [[TMP21:%.*]] = insertelement <2 x i32> [[TMP17]], i32 [[TMP20]], i64 0
// SHADERTEST-NEXT:    [[TMP22:%.*]] = bitcast <2 x i32> [[TMP21]] to i64
// SHADERTEST-NEXT:    [[TMP23:%.*]] = inttoptr i64 [[TMP22]] to ptr addrspace(4)
// SHADERTEST-NEXT:    call void @llvm.assume(i1 true) [ "align"(ptr addrspace(4) [[TMP23]], i32 4), "dereferenceable"(ptr addrspace(4) [[TMP23]], i32 -1) ]
// SHADERTEST-NEXT:    [[TMP24:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP23]], i32 656
// SHADERTEST-NEXT:    [[TMP25:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
// SHADERTEST-NEXT:    [[TMP26:%.*]] = insertelement <2 x i32> [[TMP15]], i32 [[TMP25]], i64 0
// SHADERTEST-NEXT:    [[TMP27:%.*]] = bitcast <2 x i32> [[TMP26]] to i64
// SHADERTEST-NEXT:    [[TMP28:%.*]] = inttoptr i64 [[TMP27]] to ptr addrspace(4)
// SHADERTEST-NEXT:    call void @llvm.assume(i1 true) [ "align"(ptr addrspace(4) [[TMP28]], i32 4), "dereferenceable"(ptr addrspace(4) [[TMP28]], i32 -1) ]
// SHADERTEST-NEXT:    [[TMP29:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP28]], i32 144
// SHADERTEST-NEXT:    [[TMP30:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
// SHADERTEST-NEXT:    [[TMP31:%.*]] = insertelement <2 x i32> [[TMP11]], i32 [[TMP30]], i64 0
// SHADERTEST-NEXT:    [[TMP32:%.*]] = bitcast <2 x i32> [[TMP31]] to i64
// SHADERTEST-NEXT:    [[TMP33:%.*]] = inttoptr i64 [[TMP32]] to ptr addrspace(4)
// SHADERTEST-NEXT:    call void @llvm.assume(i1 true) [ "align"(ptr addrspace(4) [[TMP33]], i32 4), "dereferenceable"(ptr addrspace(4) [[TMP33]], i32 -1) ]
// SHADERTEST-NEXT:    [[TMP34:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP33]], i32 96
// SHADERTEST-NEXT:    [[TMP35:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
// SHADERTEST-NEXT:    [[TMP36:%.*]] = insertelement <2 x i32> [[TMP13]], i32 [[TMP35]], i64 0
// SHADERTEST-NEXT:    [[TMP37:%.*]] = bitcast <2 x i32> [[TMP36]] to i64
// SHADERTEST-NEXT:    [[TMP38:%.*]] = inttoptr i64 [[TMP37]] to ptr addrspace(4)
// SHADERTEST-NEXT:    call void @llvm.assume(i1 true) [ "align"(ptr addrspace(4) [[TMP38]], i32 4), "dereferenceable"(ptr addrspace(4) [[TMP38]], i32 -1) ]
// SHADERTEST-NEXT:    [[TMP39:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP38]], i32 128
// SHADERTEST-NEXT:    [[TMP40:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
// SHADERTEST-NEXT:    [[TMP41:%.*]] = insertelement <2 x i32> [[TMP9]], i32 [[TMP40]], i64 0
// SHADERTEST-NEXT:    [[TMP42:%.*]] = bitcast <2 x i32> [[TMP41]] to i64
// SHADERTEST-NEXT:    [[TMP43:%.*]] = inttoptr i64 [[TMP42]] to ptr addrspace(4)
// SHADERTEST-NEXT:    call void @llvm.assume(i1 true) [ "align"(ptr addrspace(4) [[TMP43]], i32 4), "dereferenceable"(ptr addrspace(4) [[TMP43]], i32 -1) ]
// SHADERTEST-NEXT:    [[TMP44:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP43]], i32 80
// SHADERTEST-NEXT:    [[TMP45:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
// SHADERTEST-NEXT:    [[TMP46:%.*]] = insertelement <2 x i32> [[TMP7]], i32 [[TMP45]], i64 0
// SHADERTEST-NEXT:    [[TMP47:%.*]] = bitcast <2 x i32> [[TMP46]] to i64
// SHADERTEST-NEXT:    [[TMP48:%.*]] = inttoptr i64 [[TMP47]] to ptr addrspace(4)
// SHADERTEST-NEXT:    call void @llvm.assume(i1 true) [ "align"(ptr addrspace(4) [[TMP48]], i32 4), "dereferenceable"(ptr addrspace(4) [[TMP48]], i32 -1) ]
// SHADERTEST-NEXT:    [[TMP49:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP48]], i32 48
// SHADERTEST-NEXT:    [[TMP50:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
// SHADERTEST-NEXT:    [[TMP51:%.*]] = insertelement <2 x i32> [[TMP3]], i32 [[TMP50]], i64 0
// SHADERTEST-NEXT:    [[TMP52:%.*]] = bitcast <2 x i32> [[TMP51]] to i64
// SHADERTEST-NEXT:    [[TMP53:%.*]] = inttoptr i64 [[TMP52]] to ptr addrspace(4)
// SHADERTEST-NEXT:    call void @llvm.assume(i1 true) [ "align"(ptr addrspace(4) [[TMP53]], i32 4), "dereferenceable"(ptr addrspace(4) [[TMP53]], i32 -1) ]
// SHADERTEST-NEXT:    [[TMP54:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP53]], i32 0
// SHADERTEST-NEXT:    [[TMP55:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
// SHADERTEST-NEXT:    [[TMP56:%.*]] = insertelement <2 x i32> [[TMP5]], i32 [[TMP55]], i64 0
// SHADERTEST-NEXT:    [[TMP57:%.*]] = bitcast <2 x i32> [[TMP56]] to i64
// SHADERTEST-NEXT:    [[TMP58:%.*]] = inttoptr i64 [[TMP57]] to ptr addrspace(4)
// SHADERTEST-NEXT:    call void @llvm.assume(i1 true) [ "align"(ptr addrspace(4) [[TMP58]], i32 4), "dereferenceable"(ptr addrspace(4) [[TMP58]], i32 -1) ]
// SHADERTEST-NEXT:    [[TMP59:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP58]], i32 32
// SHADERTEST-NEXT:    [[TMP60:%.*]] = load <8 x i32>, ptr addrspace(4) [[TMP54]], align 4, !invariant.load [[META16:![0-9]+]]
// SHADERTEST-NEXT:    [[TMP61:%.*]] = load <4 x i32>, ptr addrspace(4) [[TMP59]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP62:%.*]] = call reassoc nnan nsz arcp contract afn <4 x float> @llvm.amdgcn.image.sample.2d.v4f32.f32.v8i32.v4i32(i32 15, float 0.000000e+00, float 0.000000e+00, <8 x i32> [[TMP60]], <4 x i32> [[TMP61]], i1 false, i32 0, i32 0)
// SHADERTEST-NEXT:    [[TMP63:%.*]] = load <8 x i32>, ptr addrspace(4) [[TMP49]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP64:%.*]] = load <4 x i32>, ptr addrspace(4) [[TMP44]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP65:%.*]] = call reassoc nnan nsz arcp contract afn <4 x float> @llvm.amdgcn.image.sample.2d.v4f32.f32.v8i32.v4i32(i32 15, float 0.000000e+00, float 0.000000e+00, <8 x i32> [[TMP63]], <4 x i32> [[TMP64]], i1 false, i32 0, i32 0)
// SHADERTEST-NEXT:    [[TMP66:%.*]] = fadd reassoc nnan nsz arcp contract afn <4 x float> [[TMP62]], [[TMP65]]
// SHADERTEST-NEXT:    [[TMP67:%.*]] = load <8 x i32>, ptr addrspace(4) [[TMP34]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP68:%.*]] = load <4 x i32>, ptr addrspace(4) [[TMP39]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP69:%.*]] = call reassoc nnan nsz arcp contract afn <4 x float> @llvm.amdgcn.image.sample.2d.v4f32.f32.v8i32.v4i32(i32 15, float 0.000000e+00, float 0.000000e+00, <8 x i32> [[TMP67]], <4 x i32> [[TMP68]], i1 false, i32 0, i32 0)
// SHADERTEST-NEXT:    [[TMP70:%.*]] = fadd reassoc nnan nsz arcp contract afn <4 x float> [[TMP66]], [[TMP69]]
// SHADERTEST-NEXT:    [[TMP71:%.*]] = mul i32 [[TMP19]], 32
// SHADERTEST-NEXT:    [[TMP72:%.*]] = sext i32 [[TMP71]] to i64
// SHADERTEST-NEXT:    [[TMP73:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP29]], i64 [[TMP72]]
// SHADERTEST-NEXT:    [[TMP74:%.*]] = mul i32 [[TMP18]], 16
// SHADERTEST-NEXT:    [[TMP75:%.*]] = sext i32 [[TMP74]] to i64
// SHADERTEST-NEXT:    [[TMP76:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP24]], i64 [[TMP75]]
// SHADERTEST-NEXT:    [[TMP77:%.*]] = load <8 x i32>, ptr addrspace(4) [[TMP73]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP78:%.*]] = call <8 x i32> @llvm.amdgcn.readfirstlane.v8i32(<8 x i32> [[TMP77]])
// SHADERTEST-NEXT:    [[TMP79:%.*]] = load <4 x i32>, ptr addrspace(4) [[TMP76]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP80:%.*]] = call <4 x i32> @llvm.amdgcn.readfirstlane.v4i32(<4 x i32> [[TMP79]])
// SHADERTEST-NEXT:    [[TMP81:%.*]] = call reassoc nnan nsz arcp contract afn <4 x float> @llvm.amdgcn.image.sample.2d.v4f32.f32.v8i32.v4i32(i32 15, float 0.000000e+00, float 0.000000e+00, <8 x i32> [[TMP78]], <4 x i32> [[TMP80]], i1 false, i32 0, i32 0)
// SHADERTEST-NEXT:    [[TMP82:%.*]] = fadd reassoc nnan nsz arcp contract afn <4 x float> [[TMP70]], [[TMP81]]
// SHADERTEST-NEXT:    [[TMP83:%.*]] = insertvalue { ptr addrspace(4), i32, i32, ptr addrspace(4), i32, i32 } poison, ptr addrspace(4) [[TMP73]], 0
// SHADERTEST-NEXT:    [[TMP84:%.*]] = insertvalue { ptr addrspace(4), i32, i32, ptr addrspace(4), i32, i32 } [[TMP83]], i32 32, 1
// SHADERTEST-NEXT:    [[TMP85:%.*]] = insertvalue { ptr addrspace(4), i32, i32, ptr addrspace(4), i32, i32 } [[TMP84]], i32 0, 2
// SHADERTEST-NEXT:    [[TMP86:%.*]] = insertvalue { ptr addrspace(4), i32, i32, ptr addrspace(4), i32, i32 } [[TMP85]], ptr addrspace(4) [[TMP44]], 3
// SHADERTEST-NEXT:    [[TMP87:%.*]] = insertvalue { ptr addrspace(4), i32, i32, ptr addrspace(4), i32, i32 } [[TMP86]], i32 16, 4
// SHADERTEST-NEXT:    [[TMP88:%.*]] = ptrtoint ptr addrspace(4) [[TMP73]] to i32
// SHADERTEST-NEXT:    [[TMP89:%.*]] = load <4 x i32>, ptr addrspace(4) [[TMP44]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP90:%.*]] = call <4 x i32> @llvm.amdgcn.readfirstlane.v4i32(<4 x i32> [[TMP89]])
// SHADERTEST-NEXT:    [[TMP91:%.*]] = call i32 @llvm.amdgcn.waterfall.begin.i32(i32 0, i32 [[TMP88]])
// SHADERTEST-NEXT:    [[TMP92:%.*]] = call i32 @llvm.amdgcn.waterfall.readfirstlane.i32.i32(i32 [[TMP91]], i32 [[TMP88]])
// SHADERTEST-NEXT:    [[TMP93:%.*]] = insertelement <2 x i32> [[TMP1]], i32 [[TMP92]], i64 0
// SHADERTEST-NEXT:    [[TMP94:%.*]] = bitcast <2 x i32> [[TMP93]] to i64
// SHADERTEST-NEXT:    [[TMP95:%.*]] = inttoptr i64 [[TMP94]] to ptr addrspace(4)
// SHADERTEST-NEXT:    [[TMP96:%.*]] = load <8 x i32>, ptr addrspace(4) [[TMP95]], align 4, !invariant.load [[META16]]
// SHADERTEST-NEXT:    [[TMP97:%.*]] = call reassoc nnan nsz arcp contract afn <4 x float> @llvm.amdgcn.image.sample.2d.v4f32.f32.v8i32.v4i32(i32 15, float 0.000000e+00, float 0.000000e+00, <8 x i32> [[TMP96]], <4 x i32> [[TMP90]], i1 false, i32 0, i32 0)
// SHADERTEST-NEXT:    [[TMP98:%.*]] = call reassoc nnan nsz arcp contract afn <4 x float> @llvm.amdgcn.waterfall.end.v4f32(i32 [[TMP91]], <4 x float> [[TMP97]])
// SHADERTEST-NEXT:    [[TMP99:%.*]] = fadd reassoc nnan nsz arcp contract afn <4 x float> [[TMP82]], [[TMP98]]
// SHADERTEST-NEXT:    call void @lgc.output.export.generic.i32.i32.v4f32(i32 0, i32 0, <4 x float> [[TMP99]]) #[[ATTR8:[0-9]+]]
// SHADERTEST-NEXT:    ret void
//
//.
// SHADERTEST: [[META14]] = !{i32 4}
// SHADERTEST: [[META15]] = !{i32 6}
// SHADERTEST: [[META16]] = !{}
//.
