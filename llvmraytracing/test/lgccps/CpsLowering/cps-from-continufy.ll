; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -o - -passes='lower-await,coro-early,lgc-coro-split,coro-cleanup,cleanup-continuations' %s -S | FileCheck --check-prefixes=CHECK %s

%_rgen_1.Frame = type { ptr addrspace(7), ptr addrspace(7), i32 }

define spir_func void @_rgen_1(i32 %rcr) #0 !spirv.ExecutionModel !15 !lgc.shaderstage !16 !continuation !18 !lgc.cps !17 {
; CHECK-LABEL: define spir_func void @_rgen_1(
; CHECK-SAME: i32 [[CSPINIT:%.*]], i32 [[RCR:%.*]]) #[[ATTR0:[0-9]+]] !spirv.ExecutionModel [[META16:![0-9]+]] !lgc.shaderstage [[META17:![0-9]+]] !continuation [[META18:![0-9]+]] !lgc.cps [[META19:![0-9]+]] !continuation.state [[META20:![0-9]+]] {
; CHECK-NEXT:  [[_ENTRY:.*:]]
; CHECK-NEXT:    [[CSP:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[CSPINIT]], ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP1:%.*]] = add i32 [[TMP0]], 96
; CHECK-NEXT:    store i32 [[TMP1]], ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; CHECK-NEXT:    [[TMP3:%.*]] = bitcast i64 [[TMP2]] to <2 x i32>
; CHECK-NEXT:    [[TMP4:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; CHECK-NEXT:    [[TMP5:%.*]] = bitcast i64 [[TMP4]] to <2 x i32>
; CHECK-NEXT:    [[TMP6:%.*]] = call i64 @llvm.amdgcn.s.getpc()
; CHECK-NEXT:    [[TMP7:%.*]] = bitcast i64 [[TMP6]] to <2 x i32>
; CHECK-NEXT:    [[TMP8:%.*]] = call i32 @lgc.load.user.data__i32(i32 20)
; CHECK-NEXT:    [[TMP9:%.*]] = insertelement <2 x i32> [[TMP7]], i32 [[TMP8]], i64 0
; CHECK-NEXT:    [[TMP10:%.*]] = bitcast <2 x i32> [[TMP9]] to i64
; CHECK-NEXT:    [[TMP11:%.*]] = inttoptr i64 [[TMP10]] to ptr addrspace(4)
; CHECK-NEXT:    [[TMP12:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP11]], i32 0
; CHECK-NEXT:    [[TMP13:%.*]] = load <2 x i32>, ptr addrspace(4) [[TMP12]], align 8
; CHECK-NEXT:    [[TMP14:%.*]] = extractelement <2 x i32> [[TMP13]], i64 0
; CHECK-NEXT:    [[TMP15:%.*]] = extractelement <2 x i32> [[TMP13]], i64 1
; CHECK-NEXT:    [[TMP16:%.*]] = insertelement <4 x i32> poison, i32 [[TMP14]], i64 0
; CHECK-NEXT:    [[TMP17:%.*]] = and i32 [[TMP15]], 65535
; CHECK-NEXT:    [[TMP18:%.*]] = insertelement <4 x i32> [[TMP16]], i32 [[TMP17]], i64 1
; CHECK-NEXT:    [[TMP19:%.*]] = insertelement <4 x i32> [[TMP18]], i32 -1, i64 2
; CHECK-NEXT:    [[TMP20:%.*]] = insertelement <4 x i32> [[TMP19]], i32 553734060, i64 3
; CHECK-NEXT:    [[TMP21:%.*]] = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> [[TMP20]], i1 false)
; CHECK-NEXT:    [[TMP22:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
; CHECK-NEXT:    [[TMP23:%.*]] = insertelement <2 x i32> [[TMP5]], i32 [[TMP22]], i64 0
; CHECK-NEXT:    [[TMP24:%.*]] = bitcast <2 x i32> [[TMP23]] to i64
; CHECK-NEXT:    [[TMP25:%.*]] = inttoptr i64 [[TMP24]] to ptr addrspace(4)
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP25]], i32 32
; CHECK-NEXT:    [[TMP27:%.*]] = load <4 x i32>, ptr addrspace(4) [[TMP26]], align 16
; CHECK-NEXT:    [[TMP28:%.*]] = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> [[TMP27]], i1 false)
; CHECK-NEXT:    [[TMP29:%.*]] = inttoptr i32 [[TMP0]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP30:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP29]], i32 0
; CHECK-NEXT:    store ptr addrspace(7) [[TMP28]], ptr addrspace(5) [[TMP30]], align 32
; CHECK-NEXT:    [[TMP31:%.*]] = call i32 @lgc.load.user.data__i32(i32 0)
; CHECK-NEXT:    [[TMP32:%.*]] = insertelement <2 x i32> [[TMP3]], i32 [[TMP31]], i64 0
; CHECK-NEXT:    [[TMP33:%.*]] = bitcast <2 x i32> [[TMP32]] to i64
; CHECK-NEXT:    [[TMP34:%.*]] = inttoptr i64 [[TMP33]] to ptr addrspace(4)
; CHECK-NEXT:    [[TMP35:%.*]] = getelementptr i8, ptr addrspace(4) [[TMP34]], i32 48
; CHECK-NEXT:    [[TMP36:%.*]] = load <4 x i32>, ptr addrspace(4) [[TMP35]], align 16
; CHECK-NEXT:    [[TMP37:%.*]] = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> [[TMP36]], i1 false)
; CHECK-NEXT:    [[TMP38:%.*]] = add i32 [[TMP0]], 8
; CHECK-NEXT:    [[TMP39:%.*]] = inttoptr i32 [[TMP38]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP40:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP39]], i32 0
; CHECK-NEXT:    store ptr addrspace(7) [[TMP37]], ptr addrspace(5) [[TMP40]], align 32
; CHECK-NEXT:    [[TMP41:%.*]] = load volatile i32, ptr addrspace(7) [[TMP37]], align 4
; CHECK-NEXT:    [[TMP42:%.*]] = add i32 [[TMP0]], 16
; CHECK-NEXT:    [[TMP43:%.*]] = inttoptr i32 [[TMP42]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP44:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP43]], i32 0
; CHECK-NEXT:    store i32 [[TMP41]], ptr addrspace(5) [[TMP44]], align 4
; CHECK-NEXT:    [[TMP45:%.*]] = add i32 [[TMP41]], -37
; CHECK-NEXT:    [[TMP46:%.*]] = getelementptr inbounds i8, ptr addrspace(7) [[TMP21]], i32 52
; CHECK-NEXT:    [[TMP47:%.*]] = load i64, ptr addrspace(7) [[TMP46]], align 8
; CHECK-NEXT:    [[TMP48:%.*]] = getelementptr inbounds i8, ptr addrspace(7) [[TMP21]], i32 60
; CHECK-NEXT:    [[TMP49:%.*]] = load i32, ptr addrspace(7) [[TMP48]], align 4
; CHECK-NEXT:    [[TMP50:%.*]] = mul i32 [[TMP45]], [[TMP49]]
; CHECK-NEXT:    [[TMP51:%.*]] = inttoptr i64 [[TMP47]] to ptr addrspace(1)
; CHECK-NEXT:    [[TMP52:%.*]] = sext i32 [[TMP50]] to i64
; CHECK-NEXT:    [[TMP53:%.*]] = getelementptr i8, ptr addrspace(1) [[TMP51]], i64 [[TMP52]]
; CHECK-NEXT:    [[TMP54:%.*]] = load i64, ptr addrspace(1) [[TMP53]], align 8
; CHECK-NEXT:    [[TMP55:%.*]] = inttoptr i64 [[TMP54]] to ptr
; CHECK-NEXT:    [[TMP56:%.*]] = ptrtoint ptr [[TMP55]] to i32
; CHECK-NEXT:    [[TMP57:%.*]] = or i32 [[TMP56]], 1
; CHECK-NEXT:    [[TMP58:%.*]] = inttoptr i32 [[TMP57]] to ptr
; CHECK-NEXT:    [[TMP59:%.*]] = call i32 (...) @lgc.cps.as.continuation.reference(ptr @_rgen_1.resume.0)
; CHECK-NEXT:    [[TMP60:%.*]] = load i32, ptr [[CSP]], align 4
; CHECK-NEXT:    call void (...) @lgc.cps.jump(i32 [[TMP57]], i32 2, i32 [[TMP60]], i32 poison, i32 [[TMP59]], [1 x i32] undef, i32 [[TMP45]])
; CHECK-NEXT:    unreachable
;
.entry:
  %0 = call ptr addrspace(32) @lgc.cps.alloc(i32 96)
  %1 = call i64 @llvm.amdgcn.s.getpc()
  %2 = bitcast i64 %1 to <2 x i32>
  %3 = call i64 @llvm.amdgcn.s.getpc()
  %4 = bitcast i64 %3 to <2 x i32>
  %5 = call i64 @llvm.amdgcn.s.getpc()
  %6 = bitcast i64 %5 to <2 x i32>
  %7 = call i32 @lgc.load.user.data__i32(i32 20)
  %8 = insertelement <2 x i32> %6, i32 %7, i64 0
  %9 = bitcast <2 x i32> %8 to i64
  %10 = inttoptr i64 %9 to ptr addrspace(4)
  %11 = getelementptr i8, ptr addrspace(4) %10, i32 0
  %12 = load <2 x i32>, ptr addrspace(4) %11, align 8
  %13 = extractelement <2 x i32> %12, i64 0
  %14 = extractelement <2 x i32> %12, i64 1
  %15 = insertelement <4 x i32> poison, i32 %13, i64 0
  %16 = and i32 %14, 65535
  %17 = insertelement <4 x i32> %15, i32 %16, i64 1
  %18 = insertelement <4 x i32> %17, i32 -1, i64 2
  %19 = insertelement <4 x i32> %18, i32 553734060, i64 3
  %20 = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> %19, i1 false)
  %21 = call i32 @lgc.load.user.data__i32(i32 0)
  %22 = insertelement <2 x i32> %4, i32 %21, i64 0
  %23 = bitcast <2 x i32> %22 to i64
  %24 = inttoptr i64 %23 to ptr addrspace(4)
  %25 = getelementptr i8, ptr addrspace(4) %24, i32 32
  %26 = load <4 x i32>, ptr addrspace(4) %25, align 16
  %27 = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> %26, i1 false)
  %28 = getelementptr inbounds %_rgen_1.Frame, ptr addrspace(32) %0, i32 0, i32 0
  store ptr addrspace(7) %27, ptr addrspace(32) %28, align 32
  %29 = call i32 @lgc.load.user.data__i32(i32 0)
  %30 = insertelement <2 x i32> %2, i32 %29, i64 0
  %31 = bitcast <2 x i32> %30 to i64
  %32 = inttoptr i64 %31 to ptr addrspace(4)
  %33 = getelementptr i8, ptr addrspace(4) %32, i32 48
  %34 = load <4 x i32>, ptr addrspace(4) %33, align 16
  %35 = call ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32> %34, i1 false)
  %36 = getelementptr inbounds %_rgen_1.Frame, ptr addrspace(32) %0, i32 0, i32 1
  store ptr addrspace(7) %35, ptr addrspace(32) %36, align 32
  %37 = load volatile i32, ptr addrspace(7) %35, align 4
  %38 = getelementptr inbounds %_rgen_1.Frame, ptr addrspace(32) %0, i32 0, i32 2
  store i32 %37, ptr addrspace(32) %38, align 4
  %39 = add i32 %37, -37
  %40 = getelementptr inbounds i8, ptr addrspace(7) %20, i32 52
  %41 = load i64, ptr addrspace(7) %40, align 8
  %42 = getelementptr inbounds i8, ptr addrspace(7) %20, i32 60
  %43 = load i32, ptr addrspace(7) %42, align 4
  %44 = mul i32 %39, %43
  %45 = inttoptr i64 %41 to ptr addrspace(1)
  %46 = sext i32 %44 to i64
  %47 = getelementptr i8, ptr addrspace(1) %45, i64 %46
  %48 = load i64, ptr addrspace(1) %47, align 8
  %49 = inttoptr i64 %48 to ptr
  %50 = ptrtoint ptr %49 to i32
  %51 = or i32 %50, 1
  %52 = inttoptr i32 %51 to ptr
  %53 = call i32 (...) @lgc.cps.as.continuation.reference(ptr @_rgen_1.resume.0)
  call void (...) @lgc.cps.jump(i32 %51, i32 2, i32 poison, i32 poison, i32 %53, [1 x i32] undef, i32 %39)
  unreachable
}

define void @_rgen_1.resume.0(i32 %1, [1 x i32] %2) !spirv.ExecutionModel !15 !lgc.shaderstage !16 !continuation !18 !lgc.cps !17 {
; CHECK-LABEL: define void @_rgen_1.resume.0(
; CHECK-SAME: i32 [[CSPINIT:%.*]], i32 [[TMP0:%.*]], [1 x i32] [[TMP1:%.*]]) !spirv.ExecutionModel [[META16]] !lgc.shaderstage [[META17]] !continuation [[META21:![0-9]+]] !lgc.cps [[META19]] !continuation.state [[META20]] {
; CHECK-NEXT:  [[ENTRYRESUME_0:.*:]]
; CHECK-NEXT:    [[CSP:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[CSPINIT]], ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = add i32 [[TMP2]], -96
; CHECK-NEXT:    [[TMP4:%.*]] = add i32 [[TMP3]], 16
; CHECK-NEXT:    [[TMP5:%.*]] = inttoptr i32 [[TMP4]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP5]], i32 0
; CHECK-NEXT:    [[DOTRELOAD6:%.*]] = load i32, ptr addrspace(5) [[TMP6]], align 4
; CHECK-NEXT:    [[TMP7:%.*]] = add i32 [[TMP3]], 8
; CHECK-NEXT:    [[TMP8:%.*]] = inttoptr i32 [[TMP7]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP8]], i32 0
; CHECK-NEXT:    [[DOTRELOAD3:%.*]] = load ptr addrspace(7), ptr addrspace(5) [[TMP9]], align 32
; CHECK-NEXT:    [[TMP10:%.*]] = inttoptr i32 [[TMP3]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP10]], i32 0
; CHECK-NEXT:    [[DOTRELOAD:%.*]] = load ptr addrspace(7), ptr addrspace(5) [[TMP11]], align 32
; CHECK-NEXT:    [[DUMMY_UDATA:%.*]] = call i32 @lgc.load.user.data__i32(i32 20)
; CHECK-NEXT:    [[TMP12:%.*]] = mul i32 [[DUMMY_UDATA]], 24
; CHECK-NEXT:    [[TMP13:%.*]] = add i32 [[TMP3]], [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = inttoptr i32 [[TMP13]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP15:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP14]], i32 0
; CHECK-NEXT:    [[DUMMY_RELOAD:%.*]] = load ptr addrspace(7), ptr addrspace(5) [[TMP15]], align 32
; CHECK-NEXT:    [[TMP16:%.*]] = load volatile i32, ptr addrspace(7) [[DOTRELOAD3]], align 4
; CHECK-NEXT:    [[TMP17:%.*]] = icmp eq i32 [[DOTRELOAD6]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = zext i1 [[TMP17]] to i32
; CHECK-NEXT:    store i32 [[TMP18]], ptr addrspace(7) [[DOTRELOAD]], align 4
; CHECK-NEXT:    ret void
;
entryresume.0:
  %3 = call ptr addrspace(32) @lgc.cps.peek(i32 96)
  %4 = getelementptr inbounds %_rgen_1.Frame, ptr addrspace(32) %3, i32 0, i32 2
  %.reload6 = load i32, ptr addrspace(32) %4, align 4
  %5 = getelementptr inbounds %_rgen_1.Frame, ptr addrspace(32) %3, i32 0, i32 1
  %.reload3 = load ptr addrspace(7), ptr addrspace(32) %5, align 32
  %6 = getelementptr inbounds %_rgen_1.Frame, ptr addrspace(32) %3, i32 0, i32 0
  %.reload = load ptr addrspace(7), ptr addrspace(32) %6, align 32
  %dummy.udata = call i32 @lgc.load.user.data__i32(i32 20)
  %dummy.gep = getelementptr inbounds %_rgen_1.Frame, ptr addrspace(32) %3, i32 %dummy.udata, i32 0
  %dummy.reload = load ptr addrspace(7), ptr addrspace(32) %dummy.gep, align 32
  %7 = load volatile i32, ptr addrspace(7) %.reload3, align 4
  %8 = icmp eq i32 %.reload6, %7
  %9 = zext i1 %8 to i32
  store i32 %9, ptr addrspace(7) %.reload, align 4
  call void @lgc.cps.complete()
  unreachable
}

declare i32 @lgc.load.user.data__i32(i32) #1

declare i64 @llvm.amdgcn.s.getpc() #2

declare ptr addrspace(7) @lgc.buffer.desc.to.ptr(<4 x i32>, i1) #1

declare ptr addrspace(32) @lgc.cps.alloc(i32) #6

declare i32 @lgc.cps.as.continuation.reference(...) #3

declare void @lgc.cps.jump(...) #5

declare ptr addrspace(32) @lgc.cps.peek(i32) #7

declare void @lgc.cps.complete()

attributes #0 = { alwaysinline nounwind "target-features"=",+wavefrontsize32" }
attributes #1 = { nounwind willreturn memory(none) }
attributes #2 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #3 = { nounwind willreturn }
attributes #4 = { nounwind }
attributes #5 = { noreturn }
attributes #6 = { nounwind willreturn memory(inaccessiblemem: readwrite) }
attributes #7 = { nounwind willreturn memory(inaccessiblemem: read) }

!llpc.compute.mode = !{!0}
!lgc.client = !{!1}
!lgc.options = !{!2}
!lgc.options.CS = !{!3}
!lgc.user.data.nodes = !{!4, !5, !6, !7, !8, !9, !10, !11, !12, !13}
!amdgpu.pal.metadata.msgpack = !{!14}
!continuation.stackAddrspace = !{!19}

!0 = !{i32 8, i32 4, i32 1}
!1 = !{!"Vulkan"}
!2 = !{i32 262875531, i32 502344192, i32 854861601, i32 -1595331954, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 -1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 16777216, i32 0, i32 0, i32 2}
!3 = !{i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 192, i32 0, i32 0, i32 32, i32 64, i32 0, i32 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 20, i32 1800, i32 0, i32 0, i32 1}
!4 = !{!"DescriptorTableVaPtr", i32 7, i32 0, i32 0, i32 1, i32 4}
!5 = !{!"DescriptorBuffer", i32 6, i32 0, i32 0, i32 4, i64 0, i32 0, i32 4}
!6 = !{!"DescriptorBuffer", i32 6, i32 0, i32 4, i32 4, i64 0, i32 1, i32 4}
!7 = !{!"DescriptorBuffer", i32 6, i32 0, i32 8, i32 4, i64 0, i32 2, i32 4}
!8 = !{!"DescriptorBuffer", i32 6, i32 0, i32 12, i32 4, i64 0, i32 3, i32 4}
!9 = !{!"StreamOutTableVaPtr", i32 11, i32 0, i32 1, i32 1, i32 0}
!10 = !{!"DescriptorTableVaPtr", i32 7, i32 0, i32 5, i32 1, i32 3}
!11 = !{!"DescriptorBufferCompact", i32 10, i32 0, i32 0, i32 2, i64 93, i32 17, i32 2}
!12 = !{!"DescriptorBuffer", i32 6, i32 0, i32 2, i32 4, i64 93, i32 0, i32 4}
!13 = !{!"DescriptorBuffer", i32 6, i32 0, i32 6, i32 4, i64 93, i32 1, i32 4}
!14 = !{!"\82\B0amdpal.pipelines\91\83\B0.spill_threshold\CD\FF\FF\B0.user_data_limit\00\AF.xgl_cache_info\82\B3.128_bit_cache_hash\92\CF\C4jyX\05\E6M\0F\CF\03b\DD\05\C5\B6\DB\B9\AD.llpc_version\A467.0\AEamdpal.version\92\03\00"}
!15 = !{i32 5313}
!16 = !{i32 7}
!17 = !{i32 1}
!18 = !{ptr @_rgen_1}
!19 = !{i32 5}
;.
; CHECK: [[META16]] = !{i32 5313}
; CHECK: [[META17]] = !{i32 7}
; CHECK: [[META18]] = !{ptr @_rgen_1}
; CHECK: [[META19]] = !{i32 1}
; CHECK: [[META20]] = !{i32 0}
; CHECK: [[META21]] = !{ptr @_rgen_1.resume.0}
;.
