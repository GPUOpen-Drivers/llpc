; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --include-generated-funcs --version 3
; RUN: opt --verify-each -S -o - -passes='cgscc(inline),cleanup-continuations' %s | FileCheck --check-prefixes=CHECK %s

!lgc.cps.module = !{}

declare !lgc.cps !0 void @callee({}, i32, float)

declare i64 @getVal64()
declare void @useVal64(i64)
declare i32 @getVal32()
declare void @useVal32(i32)
declare void @useValF32(float)
declare i8 @getVal8()
declare void @useVal8(i8)

; Calls getVal32() to obtain a value, and writes it
; to the given offset in data.
define void @storeToOffsetI32(ptr %data, i32 %offset) #4 {
  %val = call i32 @getVal32()
  %addr = getelementptr i8, ptr %data, i32 %offset
  store i32 %val, ptr %addr, align 2
  ret void
}

; I8 version store
define void @storeToOffsetI8(ptr %data, i32 %offset) #4 {
  %val = call i8 @getVal8()
  %addr = getelementptr i8, ptr %data, i32 %offset
  store i8 %val, ptr %addr
  ret void
}

; I64 version store
define void @storeToOffsetI64(ptr %data, i32 %offset) #4 {
  %val = call i64 @getVal64()
  %addr = getelementptr i8, ptr %data, i32 %offset
  store i64 %val, ptr %addr
  ret void
}

; Loads the value in data at the given offset, and
; feeds it into useVal32().
define void @loadAtOffsetI32(ptr %data, i32 %offset) #4 {
  %addr = getelementptr i8, ptr %data, i32 %offset
  %val.reload = load i32, ptr %addr
  call void @useVal32(i32 %val.reload)
  ret void
}

; I64 version load
define void @loadAtOffsetI64(ptr %data, i32 %offset) #4 {
  %addr = getelementptr i8, ptr %data, i32 %offset
  %val.reload = load i32, ptr %addr
  call void @useVal32(i32 %val.reload)
  ret void
}

; F32 version load
define void @loadAtOffsetF32(ptr %data, i32 %offset) #4 {
  %addr = getelementptr i8, ptr %data, i32 %offset
  %val.reload = load float, ptr %addr
  call void @useValF32(float %val.reload)
  ret void
}

%test.Frame = type { i32, float, [100 x i32] }

define { ptr, ptr } @test(i32 %shaderIndex, i32 %rcr, float %arg, ptr %0) !lgc.cps !0 !continuation !1 {
entry:
  %1 = call ptr @continuation.malloc(i32 408)
  store ptr %1, ptr %0, align 8

  %arg.spill.addr = getelementptr inbounds %test.Frame, ptr %1, i32 0, i32 1
  store float %arg, ptr %arg.spill.addr, align 4
  %rcr.spill.addr = getelementptr inbounds %test.Frame, ptr %1, i32 0, i32 0
  store i32 %rcr, ptr %rcr.spill.addr, align 4

  %t0 = fadd float %arg, 1.000000e+00
  %cr = call i32 @lgc.cps.as.continuation.reference(ptr @callee)
  %cond = fcmp olt float %t0, 1.000000e+00
  %data = getelementptr inbounds %test.Frame, ptr %1, i32 0, i32 2

  ; Matching load/store pair at offset 0 in data. range: [0, 4)
  call void @storeToOffsetI32(ptr %data, i32 0)

  ; Double store, no forwarding (even though we could, the second dominates the load)
  call void @storeToOffsetI32(ptr %data, i32 4)
  call void @storeToOffsetI32(ptr %data, i32 4)

  ; Store with conflicting store at the start point
  call void @storeToOffsetI32(ptr %data, i32 10)
  call void @storeToOffsetI32(ptr %data, i32 12)

  ; Store with conflicting store at the end point
  call void @storeToOffsetI32(ptr %data, i32 16)
  call void @storeToOffsetI32(ptr %data, i32 18)

  ; Store with conflicting store strictly inside its range
  call void @storeToOffsetI32(ptr %data, i32 24)
  call void @storeToOffsetI8(ptr %data, i32 25)

  ; Load from part of the store range
  call void @storeToOffsetI64(ptr %data, i32 28)

  ; Type mismatch
  call void @storeToOffsetI32(ptr %data, i32 36)

  ; Store does not dominate load
  call void @loadAtOffsetI32(ptr %data, i32 40)

  ; Check tightly packed loads/stores can be optimized correctly
  call void @storeToOffsetI32(ptr %data, i32 44)
  call void @storeToOffsetI32(ptr %data, i32 48)
  br i1 %cond, label %bb1, label %bb2

bb1:                                              ; preds = %entry
  %2 = inttoptr i32 %cr to ptr
  %3 = call ptr %2(i32 %cr, i32 3, i32 2, float %arg), !continuation.returnedRegistercount !{i32 0}
  %4 = insertvalue { ptr, ptr } undef, ptr @test.resume.0, 0
  %5 = insertvalue { ptr, ptr } %4, ptr %3, 1
  ret { ptr, ptr } %5

bb2:                                              ; preds = %entry
  %t0.bb2 = phi float [ %t0, %entry ]
  %arg.reload.addr = getelementptr inbounds %test.Frame, ptr %1, i32 0, i32 1
  %arg.reload = load float, ptr %arg.reload.addr, align 4
  %rcr.reload.addr = getelementptr inbounds %test.Frame, ptr %1, i32 0, i32 0
  %rcr.reload = load i32, ptr %rcr.reload.addr, align 4
  %returnvalue = fmul float %t0.bb2, %arg.reload

  ; Perfect eliminated case
  call void @loadAtOffsetI32(ptr %data, i32 0)

  ; Double store, no forwarding (even though we could, the second dominates the load)
  call void @loadAtOffsetI32(ptr %data, i32 4)

  ; Store with conflicting store at the start point
  call void @loadAtOffsetI32(ptr %data, i32 12)

  ; Store with conflicting store at the end point
  call void @loadAtOffsetI32(ptr %data, i32 16)

  ; Store with conflicting store strictly inside its range
  call void @loadAtOffsetI32(ptr %data, i32 24)

  ; Load from part of the store range
  call void @loadAtOffsetI32(ptr %data, i32 32)

  ; Type mismatch
  call void @loadAtOffsetF32(ptr %data, i32 36)

  ; Store does not dominate load
  call void @storeToOffsetI32(ptr %data, i32 40)

  ; Check tightly packed loads/stores can be optimized correctly
  call void @loadAtOffsetI32(ptr %data, i32 44)
  call void @loadAtOffsetI32(ptr %data, i32 48)

  ; Multiple loads can be optimized away
  call void @loadAtOffsetI32(ptr %data, i32 48)

  call void (...) @lgc.cps.jump(i32 %rcr.reload, i32 2, i32 poison, i32 poison, i32 poison, float %returnvalue)
  unreachable
}

define internal { ptr, ptr } @test.resume.0(ptr noalias noundef nonnull align 4 dereferenceable(8) %0, i1 %1) !lgc.cps !0 !continuation !1 {
entryresume.0:
  %2 = load ptr, ptr %0, align 8
  %3 = call { i32, float } @lgc.ilcps.getReturnValue__i32_f32()
  %ret.arg = extractvalue { i32, float } %3, 1
  %arg.reload.addr = getelementptr inbounds %test.Frame, ptr %2, i32 0, i32 1
  %arg.reload = load float, ptr %arg.reload.addr, align 4
  %rcr.reload.addr = getelementptr inbounds %test.Frame, ptr %2, i32 0, i32 0
  %rcr.reload = load i32, ptr %rcr.reload.addr, align 4
  %returnvalue = fmul float %ret.arg, %arg.reload
  call void (...) @lgc.cps.jump(i32 %rcr.reload, i32 2, i32 poison, i32 poison, i32 poison, float %returnvalue)
  unreachable
}

; Function Attrs: memory(none)
declare i32 @lgc.cps.as.continuation.reference(...) #0

declare void @lgc.cps.jump(...)

declare !continuation !1 { ptr, ptr } @continuation.prototype.test(ptr, i1)

declare ptr @continuation.malloc(i32)

declare void @continuation.free(ptr)

; Function Attrs: nounwind
declare token @llvm.coro.id.retcon(i32, i32, ptr, ptr, ptr, ptr) #1

; Function Attrs: nounwind
declare ptr @llvm.coro.begin(token, ptr writeonly) #1

; Function Attrs: nounwind
declare i1 @llvm.coro.suspend.retcon.i1(...) #1

; Function Attrs: nounwind willreturn
declare { i32, float } @lgc.ilcps.getReturnValue__i32_f32() #2

; Function Attrs: noreturn
declare void @continuation.return(...) #3

attributes #0 = { memory(none) }
attributes #1 = { nounwind }
attributes #2 = { nounwind willreturn }
attributes #3 = { noreturn }
attributes #4 = { alwaysinline }

!continuation.stackAddrspace = !{!2}

!0 = !{i32 1}
!1 = !{ptr @test}
!2 = !{i32 5}
; CHECK-LABEL: define void @storeToOffsetI32(
; CHECK-SAME: ptr [[DATA:%.*]], i32 [[OFFSET:%.*]]) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:    [[VAL:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[ADDR:%.*]] = getelementptr i8, ptr [[DATA]], i32 [[OFFSET]]
; CHECK-NEXT:    store i32 [[VAL]], ptr [[ADDR]], align 2
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define void @storeToOffsetI8(
; CHECK-SAME: ptr [[DATA:%.*]], i32 [[OFFSET:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    [[VAL:%.*]] = call i8 @getVal8()
; CHECK-NEXT:    [[ADDR:%.*]] = getelementptr i8, ptr [[DATA]], i32 [[OFFSET]]
; CHECK-NEXT:    store i8 [[VAL]], ptr [[ADDR]], align 1
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define void @storeToOffsetI64(
; CHECK-SAME: ptr [[DATA:%.*]], i32 [[OFFSET:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    [[VAL:%.*]] = call i64 @getVal64()
; CHECK-NEXT:    [[ADDR:%.*]] = getelementptr i8, ptr [[DATA]], i32 [[OFFSET]]
; CHECK-NEXT:    store i64 [[VAL]], ptr [[ADDR]], align 4
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define void @loadAtOffsetI32(
; CHECK-SAME: ptr [[DATA:%.*]], i32 [[OFFSET:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    [[ADDR:%.*]] = getelementptr i8, ptr [[DATA]], i32 [[OFFSET]]
; CHECK-NEXT:    [[VAL_RELOAD:%.*]] = load i32, ptr [[ADDR]], align 4
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_RELOAD]])
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define void @loadAtOffsetI64(
; CHECK-SAME: ptr [[DATA:%.*]], i32 [[OFFSET:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    [[ADDR:%.*]] = getelementptr i8, ptr [[DATA]], i32 [[OFFSET]]
; CHECK-NEXT:    [[VAL_RELOAD:%.*]] = load i32, ptr [[ADDR]], align 4
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_RELOAD]])
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define void @loadAtOffsetF32(
; CHECK-SAME: ptr [[DATA:%.*]], i32 [[OFFSET:%.*]]) #[[ATTR0]] {
; CHECK-NEXT:    [[ADDR:%.*]] = getelementptr i8, ptr [[DATA]], i32 [[OFFSET]]
; CHECK-NEXT:    [[VAL_RELOAD:%.*]] = load float, ptr [[ADDR]], align 4
; CHECK-NEXT:    call void @useValF32(float [[VAL_RELOAD]])
; CHECK-NEXT:    ret void
;
;
; CHECK-LABEL: define void @test(
; CHECK-SAME: i32 [[CSPINIT:%.*]], i32 [[SHADERINDEX:%.*]], i32 [[RCR:%.*]], float [[ARG:%.*]]) !lgc.cps [[META1:![0-9]+]] !continuation [[META2:![0-9]+]] !continuation.stacksize [[META3:![0-9]+]] !continuation.state [[META3]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[TMP51:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[CSPINIT]], ptr [[TMP51]], align 4
; CHECK-NEXT:    [[TMP2:%.*]] = load i32, ptr [[TMP51]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = add i32 [[TMP2]], 408
; CHECK-NEXT:    store i32 [[TMP3]], ptr [[TMP51]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = add i32 [[TMP2]], 4
; CHECK-NEXT:    [[TMP7:%.*]] = inttoptr i32 [[TMP4]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP7]], i32 0
; CHECK-NEXT:    store float [[ARG]], ptr addrspace(5) [[TMP6]], align 4
; CHECK-NEXT:    [[TMP5:%.*]] = inttoptr i32 [[TMP2]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP5]], i32 0
; CHECK-NEXT:    store i32 [[RCR]], ptr addrspace(5) [[TMP8]], align 4
; CHECK-NEXT:    [[T0:%.*]] = fadd float [[ARG]], 1.000000e+00
; CHECK-NEXT:    [[CR:%.*]] = call i32 @lgc.cps.as.continuation.reference(ptr @callee)
; CHECK-NEXT:    [[COND:%.*]] = fcmp olt float [[T0]], 1.000000e+00
; CHECK-NEXT:    [[TMP9:%.*]] = add i32 [[TMP2]], 8
; CHECK-NEXT:    [[VAL_I:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP10:%.*]] = inttoptr i32 [[TMP9]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP11:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP10]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I]], ptr addrspace(5) [[TMP11]], align 2
; CHECK-NEXT:    [[VAL_I1:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP12:%.*]] = add i32 [[TMP9]], 4
; CHECK-NEXT:    [[TMP13:%.*]] = inttoptr i32 [[TMP12]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP14:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP13]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I1]], ptr addrspace(5) [[TMP14]], align 2
; CHECK-NEXT:    [[VAL_I2:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP15:%.*]] = add i32 [[TMP9]], 4
; CHECK-NEXT:    [[TMP16:%.*]] = inttoptr i32 [[TMP15]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP16]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I2]], ptr addrspace(5) [[TMP17]], align 2
; CHECK-NEXT:    [[VAL_I4:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP18:%.*]] = add i32 [[TMP9]], 10
; CHECK-NEXT:    [[TMP19:%.*]] = inttoptr i32 [[TMP18]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP20:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP19]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I4]], ptr addrspace(5) [[TMP20]], align 2
; CHECK-NEXT:    [[VAL_I6:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP21:%.*]] = add i32 [[TMP9]], 12
; CHECK-NEXT:    [[TMP22:%.*]] = inttoptr i32 [[TMP21]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP22]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I6]], ptr addrspace(5) [[TMP23]], align 2
; CHECK-NEXT:    [[VAL_I8:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP24:%.*]] = add i32 [[TMP9]], 16
; CHECK-NEXT:    [[TMP25:%.*]] = inttoptr i32 [[TMP24]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP26:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP25]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I8]], ptr addrspace(5) [[TMP26]], align 2
; CHECK-NEXT:    [[VAL_I10:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP27:%.*]] = add i32 [[TMP9]], 18
; CHECK-NEXT:    [[TMP28:%.*]] = inttoptr i32 [[TMP27]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP29:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP28]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I10]], ptr addrspace(5) [[TMP29]], align 2
; CHECK-NEXT:    [[VAL_I12:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP30:%.*]] = add i32 [[TMP9]], 24
; CHECK-NEXT:    [[TMP31:%.*]] = inttoptr i32 [[TMP30]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP32:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP31]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I12]], ptr addrspace(5) [[TMP32]], align 2
; CHECK-NEXT:    [[VAL_I14:%.*]] = call i8 @getVal8()
; CHECK-NEXT:    [[TMP33:%.*]] = add i32 [[TMP9]], 25
; CHECK-NEXT:    [[TMP34:%.*]] = inttoptr i32 [[TMP33]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP35:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP34]], i32 0
; CHECK-NEXT:    store i8 [[VAL_I14]], ptr addrspace(5) [[TMP35]], align 1
; CHECK-NEXT:    [[VAL_I16:%.*]] = call i64 @getVal64()
; CHECK-NEXT:    [[TMP36:%.*]] = add i32 [[TMP9]], 28
; CHECK-NEXT:    [[TMP37:%.*]] = inttoptr i32 [[TMP36]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP38:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP37]], i32 0
; CHECK-NEXT:    store i64 [[VAL_I16]], ptr addrspace(5) [[TMP38]], align 4
; CHECK-NEXT:    [[VAL_I18:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP39:%.*]] = add i32 [[TMP9]], 36
; CHECK-NEXT:    [[TMP40:%.*]] = inttoptr i32 [[TMP39]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP41:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP40]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I18]], ptr addrspace(5) [[TMP41]], align 2
; CHECK-NEXT:    [[TMP42:%.*]] = add i32 [[TMP9]], 40
; CHECK-NEXT:    [[TMP43:%.*]] = inttoptr i32 [[TMP42]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP44:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP43]], i32 0
; CHECK-NEXT:    [[VAL_RELOAD_I:%.*]] = load i32, ptr addrspace(5) [[TMP44]], align 4
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_RELOAD_I]])
; CHECK-NEXT:    [[VAL_I21:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP45:%.*]] = add i32 [[TMP9]], 44
; CHECK-NEXT:    [[TMP46:%.*]] = inttoptr i32 [[TMP45]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP47:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP46]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I21]], ptr addrspace(5) [[TMP47]], align 2
; CHECK-NEXT:    [[VAL_I23:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP48:%.*]] = add i32 [[TMP9]], 48
; CHECK-NEXT:    [[TMP49:%.*]] = inttoptr i32 [[TMP48]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP50:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP49]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I23]], ptr addrspace(5) [[TMP50]], align 2
; CHECK-NEXT:    br i1 [[COND]], label [[BB1:%.*]], label [[BB2:%.*]]
; CHECK:       bb1:
; CHECK-NEXT:    [[TMP0:%.*]] = inttoptr i32 [[CR]] to ptr
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 (...) @lgc.cps.as.continuation.reference(ptr @test.resume.0)
; CHECK-NEXT:    [[TMP52:%.*]] = load i32, ptr [[TMP51]], align 4
; CHECK-NEXT:    call void (...) @lgc.cps.jump(i32 [[CR]], i32 3, i32 [[TMP52]], i32 2, i32 [[TMP1]], float [[ARG]]), !continuation.returnedRegistercount [[META4:![0-9]+]]
; CHECK-NEXT:    unreachable
; CHECK:       bb2:
; CHECK-NEXT:    [[T0_BB2:%.*]] = phi float [ [[T0]], [[ENTRY:%.*]] ]
; CHECK-NEXT:    [[RETURNVALUE:%.*]] = fmul float [[T0_BB2]], [[ARG]]
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_I]])
; CHECK-NEXT:    [[TMP55:%.*]] = add i32 [[TMP9]], 4
; CHECK-NEXT:    [[TMP53:%.*]] = inttoptr i32 [[TMP55]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP57:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP53]], i32 0
; CHECK-NEXT:    [[VAL_RELOAD_I27:%.*]] = load i32, ptr addrspace(5) [[TMP57]], align 4
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_RELOAD_I27]])
; CHECK-NEXT:    [[TMP58:%.*]] = add i32 [[TMP9]], 12
; CHECK-NEXT:    [[TMP56:%.*]] = inttoptr i32 [[TMP58]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP60:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP56]], i32 0
; CHECK-NEXT:    [[VAL_RELOAD_I29:%.*]] = load i32, ptr addrspace(5) [[TMP60]], align 4
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_RELOAD_I29]])
; CHECK-NEXT:    [[TMP61:%.*]] = add i32 [[TMP9]], 16
; CHECK-NEXT:    [[TMP59:%.*]] = inttoptr i32 [[TMP61]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP63:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP59]], i32 0
; CHECK-NEXT:    [[VAL_RELOAD_I31:%.*]] = load i32, ptr addrspace(5) [[TMP63]], align 4
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_RELOAD_I31]])
; CHECK-NEXT:    [[TMP64:%.*]] = add i32 [[TMP9]], 24
; CHECK-NEXT:    [[TMP62:%.*]] = inttoptr i32 [[TMP64]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP66:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP62]], i32 0
; CHECK-NEXT:    [[VAL_RELOAD_I33:%.*]] = load i32, ptr addrspace(5) [[TMP66]], align 4
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_RELOAD_I33]])
; CHECK-NEXT:    [[TMP67:%.*]] = add i32 [[TMP9]], 32
; CHECK-NEXT:    [[TMP65:%.*]] = inttoptr i32 [[TMP67]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP69:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP65]], i32 0
; CHECK-NEXT:    [[VAL_RELOAD_I35:%.*]] = load i32, ptr addrspace(5) [[TMP69]], align 4
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_RELOAD_I35]])
; CHECK-NEXT:    [[TMP70:%.*]] = add i32 [[TMP9]], 36
; CHECK-NEXT:    [[TMP68:%.*]] = inttoptr i32 [[TMP70]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP72:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP68]], i32 0
; CHECK-NEXT:    [[VAL_RELOAD_I37:%.*]] = load float, ptr addrspace(5) [[TMP72]], align 4
; CHECK-NEXT:    call void @useValF32(float [[VAL_RELOAD_I37]])
; CHECK-NEXT:    [[VAL_I38:%.*]] = call i32 @getVal32()
; CHECK-NEXT:    [[TMP73:%.*]] = add i32 [[TMP9]], 40
; CHECK-NEXT:    [[TMP71:%.*]] = inttoptr i32 [[TMP73]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP75:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP71]], i32 0
; CHECK-NEXT:    store i32 [[VAL_I38]], ptr addrspace(5) [[TMP75]], align 2
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_I21]])
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_I23]])
; CHECK-NEXT:    call void @useVal32(i32 [[VAL_I23]])
; CHECK-NEXT:    [[TMP76:%.*]] = load i32, ptr [[TMP51]], align 4
; CHECK-NEXT:    [[TMP74:%.*]] = add i32 [[TMP76]], -408
; CHECK-NEXT:    store i32 [[TMP74]], ptr [[TMP51]], align 4
; CHECK-NEXT:    [[TMP77:%.*]] = load i32, ptr [[TMP51]], align 4
; CHECK-NEXT:    call void (...) @lgc.cps.jump(i32 [[RCR]], i32 2, i32 [[TMP77]], i32 poison, i32 poison, float [[RETURNVALUE]])
; CHECK-NEXT:    unreachable
;
;
; CHECK-LABEL: define dso_local void @test.resume.0(
; CHECK-SAME: i32 [[CSPINIT:%.*]], i32 [[TMP0:%.*]], float [[TMP1:%.*]]) !lgc.cps [[META1]] !continuation [[META2]] !continuation.registercount [[META4]] {
; CHECK-NEXT:  entryresume.0:
; CHECK-NEXT:    [[CSP:%.*]] = alloca i32, align 4
; CHECK-NEXT:    store i32 [[CSPINIT]], ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP4:%.*]] = add i32 [[TMP3]], -408
; CHECK-NEXT:    [[TMP13:%.*]] = insertvalue { i32, float } poison, i32 [[TMP0]], 0
; CHECK-NEXT:    [[TMP14:%.*]] = insertvalue { i32, float } [[TMP13]], float [[TMP1]], 1
; CHECK-NEXT:    [[RET_ARG1:%.*]] = extractvalue { i32, float } [[TMP14]], 1
; CHECK-NEXT:    [[TMP5:%.*]] = add i32 [[TMP4]], 4
; CHECK-NEXT:    [[TMP6:%.*]] = inttoptr i32 [[TMP5]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP6]], i32 0
; CHECK-NEXT:    [[ARG_RELOAD:%.*]] = load float, ptr addrspace(5) [[TMP7]], align 4
; CHECK-NEXT:    [[TMP8:%.*]] = inttoptr i32 [[TMP4]] to ptr addrspace(5)
; CHECK-NEXT:    [[TMP9:%.*]] = getelementptr i8, ptr addrspace(5) [[TMP8]], i32 0
; CHECK-NEXT:    [[RCR_RELOAD:%.*]] = load i32, ptr addrspace(5) [[TMP9]], align 4
; CHECK-NEXT:    [[RETURNVALUE:%.*]] = fmul float [[RET_ARG1]], [[ARG_RELOAD]]
; CHECK-NEXT:    [[TMP10:%.*]] = load i32, ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP11:%.*]] = add i32 [[TMP10]], -408
; CHECK-NEXT:    store i32 [[TMP11]], ptr [[CSP]], align 4
; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[CSP]], align 4
; CHECK-NEXT:    call void (...) @lgc.cps.jump(i32 [[RCR_RELOAD]], i32 2, i32 [[TMP12]], i32 poison, i32 poison, float [[RETURNVALUE]])
; CHECK-NEXT:    unreachable
;
